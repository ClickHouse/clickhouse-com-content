"use strict";(self.webpackChunkclickhouse=self.webpackChunkclickhouse||[]).push([[54516],{3905:function(e,t,a){a.d(t,{Zo:function(){return m},kt:function(){return c}});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=p(a),c=i,k=u["".concat(s,".").concat(c)]||u[c]||d[c]||r;return a?n.createElement(k,o(o({ref:t},m),{},{components:a})):n.createElement(k,o({ref:t},m))}));function c(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,o=new Array(r);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var p=2;p<r;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},78701:function(e,t,a){a.r(t),a.d(t,{assets:function(){return m},contentTitle:function(){return s},default:function(){return c},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return d}});var n=a(87462),i=a(63366),r=(a(67294),a(3905)),o=["components"],l={sidebar_position:11,sidebar_label:"MergeTree"},s="MergeTree",p={unversionedId:"en/engines/table-engines/mergetree-family/mergetree",id:"en/engines/table-engines/mergetree-family/mergetree",title:"MergeTree",description:"table_engines-mergetree}",source:"@site/docs/en/engines/table-engines/mergetree-family/mergetree.md",sourceDirName:"en/engines/table-engines/mergetree-family",slug:"/en/engines/table-engines/mergetree-family/mergetree",permalink:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/mergetree",tags:[],version:"current",sidebarPosition:11,frontMatter:{sidebar_position:11,sidebar_label:"MergeTree"},sidebar:"tutorialSidebar",previous:{title:"MergeTree Family",permalink:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/"},next:{title:"Data Replication",permalink:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/replication"}},m={},d=[{value:"Creating a Table",id:"table_engine-mergetree-creating-a-table",level:2},{value:"Query Clauses",id:"mergetree-query-clauses",level:3},{value:"Data Storage",id:"mergetree-data-storage",level:2},{value:"Primary Keys and Indexes in Queries",id:"primary-keys-and-indexes-in-queries",level:2},{value:"Selecting the Primary Key",id:"selecting-the-primary-key",level:3},{value:"Choosing a Primary Key that Differs from the Sorting Key",id:"choosing-a-primary-key-that-differs-from-the-sorting-key",level:3},{value:"Use of Indexes and Partitions in Queries",id:"use-of-indexes-and-partitions-in-queries",level:3},{value:"Use of Index for Partially-monotonic Primary Keys",id:"use-of-index-for-partially-monotonic-primary-keys",level:3},{value:"Data Skipping Indexes",id:"table_engine-mergetree-data_skipping-indexes",level:3},{value:"Available Types of Indices",id:"available-types-of-indices",level:4},{value:"Functions Support",id:"functions-support",level:4},{value:"Projections",id:"projections",level:2},{value:"Projection Query",id:"projection-query",level:3},{value:"Projection Storage",id:"projection-storage",level:3},{value:"Query Analysis",id:"projection-query-analysis",level:3},{value:"Concurrent Data Access",id:"concurrent-data-access",level:2},{value:"TTL for Columns and Tables",id:"table_engine-mergetree-ttl",level:2},{value:"Column TTL",id:"mergetree-column-ttl",level:3},{value:"Table TTL",id:"mergetree-table-ttl",level:3},{value:"Removing Expired Data",id:"mergetree-removing-expired-data",level:3},{value:"Using Multiple Block Devices for Data Storage",id:"table_engine-mergetree-multiple-volumes",level:2},{value:"Introduction",id:"introduction",level:3},{value:"Terms",id:"terms",level:3},{value:"Configuration",id:"table_engine-mergetree-multiple-volumes_configure",level:3},{value:"Details",id:"details",level:3},{value:"Using S3 for Data Storage",id:"table_engine-mergetree-s3",level:2},{value:"Using Azure Blob Storage for Data Storage",id:"table_engine-mergetree-azure-blob-storage",level:2},{value:"Virtual Columns",id:"virtual-columns",level:2}],u={toc:d};function c(e){var t=e.components,a=(0,i.Z)(e,o);return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"table_engines-mergetree"},"MergeTree"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," engine and other engines of this family (",(0,r.kt)("inlineCode",{parentName:"p"},"*MergeTree"),") are the most robust ClickHouse table engines."),(0,r.kt)("p",null,"Engines in the ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," family are designed for inserting a very large amount of data into a table. The data is quickly written to the table part by part, then rules are applied for merging the parts in the background. This method is much more efficient than continually rewriting the data in storage during insert."),(0,r.kt)("p",null,"Main features:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Stores data sorted by primary key."),(0,r.kt)("p",{parentName:"li"},"This allows you to create a small sparse index that helps find data faster.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Partitions can be used if the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/custom-partitioning-key"},"partitioning key")," is specified."),(0,r.kt)("p",{parentName:"li"},"ClickHouse supports certain operations with partitions that are more efficient than general operations on the same data with the same result. ClickHouse also automatically cuts off the partition data where the partitioning key is specified in the query.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Data replication support."),(0,r.kt)("p",{parentName:"li"},"The family of ",(0,r.kt)("inlineCode",{parentName:"p"},"ReplicatedMergeTree")," tables provides data replication. For more information, see ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/replication"},"Data replication"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Data sampling support."),(0,r.kt)("p",{parentName:"li"},"If necessary, you can set the data sampling method in the table."))),(0,r.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"The ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/special/merge#merge"},"Merge")," engine does not belong to the ",(0,r.kt)("inlineCode",{parentName:"p"},"*MergeTree")," family."))),(0,r.kt)("h2",{id:"table_engine-mergetree-creating-a-table"},"Creating a Table"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]\n(\n    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],\n    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],\n    ...\n    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,\n    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2,\n    ...\n    PROJECTION projection_name_1 (SELECT <COLUMN LIST EXPR> [GROUP BY] [ORDER BY]),\n    PROJECTION projection_name_2 (SELECT <COLUMN LIST EXPR> [GROUP BY] [ORDER BY])\n) ENGINE = MergeTree()\nORDER BY expr\n[PARTITION BY expr]\n[PRIMARY KEY expr]\n[SAMPLE BY expr]\n[TTL expr\n    [DELETE|TO DISK 'xxx'|TO VOLUME 'xxx' [, ...] ]\n    [WHERE conditions]\n    [GROUP BY key_expr [SET v1 = aggr_func(v1) [, v2 = aggr_func(v2) ...]] ] ]\n[SETTINGS name=value, ...]\n")),(0,r.kt)("p",null,"For a description of parameters, see the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/create/table"},"CREATE query description"),"."),(0,r.kt)("h3",{id:"mergetree-query-clauses"},"Query Clauses"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"ENGINE")," \u2014 Name and parameters of the engine. ",(0,r.kt)("inlineCode",{parentName:"p"},"ENGINE = MergeTree()"),". The ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," engine does not have parameters.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY")," \u2014 The sorting key."),(0,r.kt)("p",{parentName:"li"},"A tuple of column names or arbitrary expressions. Example: ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY (CounterID, EventDate)"),"."),(0,r.kt)("p",{parentName:"li"},"ClickHouse uses the sorting key as a primary key if the primary key is not defined obviously by the ",(0,r.kt)("inlineCode",{parentName:"p"},"PRIMARY KEY")," clause."),(0,r.kt)("p",{parentName:"li"},"Use the ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY tuple()")," syntax, if you do not need sorting. See ",(0,r.kt)("a",{parentName:"p",href:"#selecting-the-primary-key"},"Selecting the Primary Key"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"PARTITION BY")," \u2014 The ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/custom-partitioning-key"},"partitioning key"),". Optional. In most cases you don't need partition key, and in most other cases you don't need partition key more granular than by months. Partitioning does not speed up queries (in contrast to the ORDER BY expression). You should never use too granular partitioning. Don't partition your data by client identifiers or names (instead make client identifier or name the first column in the ORDER BY expression)."),(0,r.kt)("p",{parentName:"li"},"For partitioning by month, use the ",(0,r.kt)("inlineCode",{parentName:"p"},"toYYYYMM(date_column)")," expression, where ",(0,r.kt)("inlineCode",{parentName:"p"},"date_column")," is a column with a date of the type ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/date"},"Date"),". The partition names here have the ",(0,r.kt)("inlineCode",{parentName:"p"},'"YYYYMM"')," format.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"PRIMARY KEY")," \u2014 The primary key if it ",(0,r.kt)("a",{parentName:"p",href:"#choosing-a-primary-key-that-differs-from-the-sorting-key"},"differs from the sorting key"),". Optional."),(0,r.kt)("p",{parentName:"li"},"By default the primary key is the same as the sorting key (which is specified by the ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY")," clause). Thus in most cases it is unnecessary to specify a separate ",(0,r.kt)("inlineCode",{parentName:"p"},"PRIMARY KEY")," clause.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"SAMPLE BY")," \u2014 An expression for sampling. Optional."),(0,r.kt)("p",{parentName:"li"},"If a sampling expression is used, the primary key must contain it. The result of a sampling expression must be an unsigned integer. Example: ",(0,r.kt)("inlineCode",{parentName:"p"},"SAMPLE BY intHash32(UserID) ORDER BY (CounterID, EventDate, intHash32(UserID))"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," \u2014 A list of rules specifying storage duration of rows and defining logic of automatic parts movement ",(0,r.kt)("a",{parentName:"p",href:"#table_engine-mergetree-multiple-volumes"},"between disks and volumes"),". Optional."),(0,r.kt)("p",{parentName:"li"},"Expression must have one ",(0,r.kt)("inlineCode",{parentName:"p"},"Date")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"DateTime")," column as a result. Example:\n",(0,r.kt)("inlineCode",{parentName:"p"},"TTL date + INTERVAL 1 DAY")),(0,r.kt)("p",{parentName:"li"},"Type of the rule ",(0,r.kt)("inlineCode",{parentName:"p"},"DELETE|TO DISK 'xxx'|TO VOLUME 'xxx'|GROUP BY")," specifies an action to be done with the part if the expression is satisfied (reaches current time): removal of expired rows, moving a part (if expression is satisfied for all rows in a part) to specified disk (",(0,r.kt)("inlineCode",{parentName:"p"},"TO DISK 'xxx'"),") or to volume (",(0,r.kt)("inlineCode",{parentName:"p"},"TO VOLUME 'xxx'"),"), or aggregating values in expired rows. Default type of the rule is removal (",(0,r.kt)("inlineCode",{parentName:"p"},"DELETE"),"). List of multiple rules can be specified, but there should be no more than one ",(0,r.kt)("inlineCode",{parentName:"p"},"DELETE")," rule."),(0,r.kt)("p",{parentName:"li"},"For more details, see ",(0,r.kt)("a",{parentName:"p",href:"#table_engine-mergetree-ttl"},"TTL for columns and tables"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"SETTINGS")," \u2014 Additional parameters that control the behavior of the ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," (optional):"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity")," \u2014 Maximum number of data rows between the marks of an index. Default value: 8192. See ",(0,r.kt)("a",{parentName:"li",href:"#mergetree-data-storage"},"Data Storage"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity_bytes")," \u2014 Maximum size of data granules in bytes. Default value: 10Mb. To restrict the granule size only by number of rows, set to 0 (not recommended). See ",(0,r.kt)("a",{parentName:"li",href:"#mergetree-data-storage"},"Data Storage"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_index_granularity_bytes")," \u2014 Min allowed size of data granules in bytes. Default value: 1024b. To provide a safeguard against accidentally creating tables with very low index_granularity_bytes. See ",(0,r.kt)("a",{parentName:"li",href:"#mergetree-data-storage"},"Data Storage"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"enable_mixed_granularity_parts")," \u2014 Enables or disables transitioning to control the granule size with the ",(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity_bytes")," setting. Before version 19.11, there was only the ",(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity")," setting for restricting granule size. The ",(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity_bytes")," setting improves ClickHouse performance when selecting data from tables with big rows (tens and hundreds of megabytes). If you have tables with big rows, you can enable this setting for the tables to improve the efficiency of ",(0,r.kt)("inlineCode",{parentName:"li"},"SELECT")," queries."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"use_minimalistic_part_header_in_zookeeper")," \u2014 Storage method of the data parts headers in ZooKeeper. If ",(0,r.kt)("inlineCode",{parentName:"li"},"use_minimalistic_part_header_in_zookeeper=1"),", then ZooKeeper stores less data. For more information, see the ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/server-configuration-parameters/settings#server-settings-use_minimalistic_part_header_in_zookeeper"},"setting description")," in \u201cServer configuration parameters\u201d."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_merge_bytes_to_use_direct_io")," \u2014 The minimum data volume for merge operation that is required for using direct I/O access to the storage disk. When merging data parts, ClickHouse calculates the total storage volume of all the data to be merged. If the volume exceeds ",(0,r.kt)("inlineCode",{parentName:"li"},"min_merge_bytes_to_use_direct_io")," bytes, ClickHouse reads and writes the data to the storage disk using the direct I/O interface (",(0,r.kt)("inlineCode",{parentName:"li"},"O_DIRECT")," option). If ",(0,r.kt)("inlineCode",{parentName:"li"},"min_merge_bytes_to_use_direct_io = 0"),", then direct I/O is disabled. Default value: ",(0,r.kt)("inlineCode",{parentName:"li"},"10 * 1024 * 1024 * 1024")," bytes.",(0,r.kt)("a",{name:"mergetree_setting-merge_with_ttl_timeout"})),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"merge_with_ttl_timeout")," \u2014 Minimum delay in seconds before repeating a merge with delete TTL. Default value: ",(0,r.kt)("inlineCode",{parentName:"li"},"14400")," seconds (4 hours)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"merge_with_recompression_ttl_timeout")," \u2014 Minimum delay in seconds before repeating a merge with recompression TTL. Default value: ",(0,r.kt)("inlineCode",{parentName:"li"},"14400")," seconds (4 hours)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"try_fetch_recompressed_part_timeout")," \u2014 Timeout (in seconds) before starting merge with recompression. During this time ClickHouse tries to fetch recompressed part from replica which assigned this merge with recompression. Default value: ",(0,r.kt)("inlineCode",{parentName:"li"},"7200")," seconds (2 hours)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"write_final_mark")," \u2014 Enables or disables writing the final index mark at the end of data part (after the last byte). Default value: 1. Don\u2019t turn it off."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"merge_max_block_size")," \u2014 Maximum number of rows in block for merge operations. Default value: 8192."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"storage_policy")," \u2014 Storage policy. See ",(0,r.kt)("a",{parentName:"li",href:"#table_engine-mergetree-multiple-volumes"},"Using Multiple Block Devices for Data Storage"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_bytes_for_wide_part"),", ",(0,r.kt)("inlineCode",{parentName:"li"},"min_rows_for_wide_part")," \u2014 Minimum number of bytes/rows in a data part that can be stored in ",(0,r.kt)("inlineCode",{parentName:"li"},"Wide")," format. You can set one, both or none of these settings. See ",(0,r.kt)("a",{parentName:"li",href:"#mergetree-data-storage"},"Data Storage"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_parts_in_total")," \u2014 Maximum number of parts in all partitions."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_compress_block_size")," \u2014 Maximum size of blocks of uncompressed data before compressing for writing to a table. You can also specify this setting in the global settings (see ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/settings/#max-compress-block-size"},"max_compress_block_size")," setting). The value specified when table is created overrides the global value for this setting."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_compress_block_size")," \u2014 Minimum size of blocks of uncompressed data required for compression when writing the next mark. You can also specify this setting in the global settings (see ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/settings/#min-compress-block-size"},"min_compress_block_size")," setting). The value specified when table is created overrides the global value for this setting."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_partitions_to_read")," \u2014 Limits the maximum number of partitions that can be accessed in one query. You can also specify setting ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/settings/merge-tree-settings#max-partitions-to-read"},"max_partitions_to_read")," in the global setting.")))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Example of Sections Setting")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"ENGINE MergeTree() PARTITION BY toYYYYMM(EventDate) ORDER BY (CounterID, EventDate, intHash32(UserID)) SAMPLE BY intHash32(UserID) SETTINGS index_granularity=8192\n")),(0,r.kt)("p",null,"In the example, we set partitioning by month."),(0,r.kt)("p",null,"We also set an expression for sampling as a hash by the user ID. This allows you to pseudorandomize the data in the table for each ",(0,r.kt)("inlineCode",{parentName:"p"},"CounterID")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"EventDate"),". If you define a ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/select/sample#select-sample-clause"},"SAMPLE")," clause when selecting the data, ClickHouse will return an evenly pseudorandom data sample for a subset of users."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity")," setting can be omitted because 8192 is the default value."),(0,r.kt)("details",{markdown:"1"},(0,r.kt)("summary",null,"Deprecated Method for Creating a Table"),(0,r.kt)("div",{className:"admonition admonition-warning alert alert--danger"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"}))),"warning")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Do not use this method in new projects. If possible, switch old projects to the method described above."))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]\n(\n    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],\n    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],\n    ...\n) ENGINE [=] MergeTree(date-column [, sampling_expression], (primary, key), index_granularity)\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"MergeTree() Parameters")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"date-column")," \u2014 The name of a column of the ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/sql-reference/data-types/date"},"Date")," type. ClickHouse automatically creates partitions by month based on this column. The partition names are in the ",(0,r.kt)("inlineCode",{parentName:"li"},'"YYYYMM"')," format."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"sampling_expression")," \u2014 An expression for sampling."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"(primary, key)")," \u2014 Primary key. Type: ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/sql-reference/data-types/tuple"},"Tuple()")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity")," \u2014 The granularity of an index. The number of data rows between the \u201cmarks\u201d of an index. The value 8192 is appropriate for most tasks.")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Example")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"MergeTree(EventDate, intHash32(UserID), (CounterID, EventDate, intHash32(UserID)), 8192)\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," engine is configured in the same way as in the example above for the main engine configuration method.")),(0,r.kt)("h2",{id:"mergetree-data-storage"},"Data Storage"),(0,r.kt)("p",null,"A table consists of data parts sorted by primary key."),(0,r.kt)("p",null,"When data is inserted in a table, separate data parts are created and each of them is lexicographically sorted by primary key. For example, if the primary key is ",(0,r.kt)("inlineCode",{parentName:"p"},"(CounterID, Date)"),", the data in the part is sorted by ",(0,r.kt)("inlineCode",{parentName:"p"},"CounterID"),", and within each ",(0,r.kt)("inlineCode",{parentName:"p"},"CounterID"),", it is ordered by ",(0,r.kt)("inlineCode",{parentName:"p"},"Date"),"."),(0,r.kt)("p",null,"Data belonging to different partitions are separated into different parts. In the background, ClickHouse merges data parts for more efficient storage. Parts belonging to different partitions are not merged. The merge mechanism does not guarantee that all rows with the same primary key will be in the same data part."),(0,r.kt)("p",null,"Data parts can be stored in ",(0,r.kt)("inlineCode",{parentName:"p"},"Wide")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"Compact")," format. In ",(0,r.kt)("inlineCode",{parentName:"p"},"Wide")," format each column is stored in a separate file in a filesystem, in ",(0,r.kt)("inlineCode",{parentName:"p"},"Compact")," format all columns are stored in one file. ",(0,r.kt)("inlineCode",{parentName:"p"},"Compact")," format can be used to increase performance of small and frequent inserts."),(0,r.kt)("p",null,"Data storing format is controlled by the ",(0,r.kt)("inlineCode",{parentName:"p"},"min_bytes_for_wide_part")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"min_rows_for_wide_part")," settings of the table engine. If the number of bytes or rows in a data part is less then the corresponding setting's value, the part is stored in ",(0,r.kt)("inlineCode",{parentName:"p"},"Compact")," format. Otherwise it is stored in ",(0,r.kt)("inlineCode",{parentName:"p"},"Wide")," format. If none of these settings is set, data parts are stored in ",(0,r.kt)("inlineCode",{parentName:"p"},"Wide")," format."),(0,r.kt)("p",null,"Each data part is logically divided into granules. A granule is the smallest indivisible data set that ClickHouse reads when selecting data. ClickHouse does not split rows or values, so each granule always contains an integer number of rows. The first row of a granule is marked with the value of the primary key for the row. For each data part, ClickHouse creates an index file that stores the marks. For each column, whether it\u2019s in the primary key or not, ClickHouse also stores the same marks. These marks let you find data directly in column files."),(0,r.kt)("p",null,"The granule size is restricted by the ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity_bytes")," settings of the table engine. The number of rows in a granule lays in the ",(0,r.kt)("inlineCode",{parentName:"p"},"[1, index_granularity]")," range, depending on the size of the rows. The size of a granule can exceed ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity_bytes")," if the size of a single row is greater than the value of the setting. In this case, the size of the granule equals the size of the row."),(0,r.kt)("h2",{id:"primary-keys-and-indexes-in-queries"},"Primary Keys and Indexes in Queries"),(0,r.kt)("p",null,"Take the ",(0,r.kt)("inlineCode",{parentName:"p"},"(CounterID, Date)")," primary key as an example. In this case, the sorting and index can be illustrated as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  Whole data:     [---------------------------------------------]\n  CounterID:      [aaaaaaaaaaaaaaaaaabbbbcdeeeeeeeeeeeeefgggggggghhhhhhhhhiiiiiiiiikllllllll]\n  Date:           [1111111222222233331233211111222222333211111112122222223111112223311122333]\n  Marks:           |      |      |      |      |      |      |      |      |      |      |\n                  a,1    a,2    a,3    b,3    e,2    e,3    g,1    h,2    i,1    i,3    l,3\n  Marks numbers:   0      1      2      3      4      5      6      7      8      9      10\n")),(0,r.kt)("p",null,"If the data query specifies:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CounterID in ('a', 'h')"),", the server reads the data in the ranges of marks ",(0,r.kt)("inlineCode",{parentName:"li"},"[0, 3)")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"[6, 8)"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CounterID IN ('a', 'h') AND Date = 3"),", the server reads the data in the ranges of marks ",(0,r.kt)("inlineCode",{parentName:"li"},"[1, 3)")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"[7, 8)"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Date = 3"),", the server reads the data in the range of marks ",(0,r.kt)("inlineCode",{parentName:"li"},"[1, 10]"),".")),(0,r.kt)("p",null,"The examples above show that it is always more effective to use an index than a full scan."),(0,r.kt)("p",null,"A sparse index allows extra data to be read. When reading a single range of the primary key, up to ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity * 2")," extra rows in each data block can be read."),(0,r.kt)("p",null,"Sparse indexes allow you to work with a very large number of table rows, because in most cases, such indexes fit in the computer\u2019s RAM."),(0,r.kt)("p",null,"ClickHouse does not require a unique primary key. You can insert multiple rows with the same primary key."),(0,r.kt)("p",null,"You can use ",(0,r.kt)("inlineCode",{parentName:"p"},"Nullable"),"-typed expressions in the ",(0,r.kt)("inlineCode",{parentName:"p"},"PRIMARY KEY")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY")," clauses but it is strongly discouraged. To allow this feature, turn on the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#allow-nullable-key"},"allow_nullable_key")," setting. The ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/select/order-by#sorting-of-special-values"},"NULLS_LAST")," principle applies for ",(0,r.kt)("inlineCode",{parentName:"p"},"NULL")," values in the ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY")," clause."),(0,r.kt)("h3",{id:"selecting-the-primary-key"},"Selecting the Primary Key"),(0,r.kt)("p",null,"The number of columns in the primary key is not explicitly limited. Depending on the data structure, you can include more or fewer columns in the primary key. This may:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Improve the performance of an index."),(0,r.kt)("p",{parentName:"li"},"If the primary key is ",(0,r.kt)("inlineCode",{parentName:"p"},"(a, b)"),", then adding another column ",(0,r.kt)("inlineCode",{parentName:"p"},"c")," will improve the performance if the following conditions are met:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"There are queries with a condition on column ",(0,r.kt)("inlineCode",{parentName:"li"},"c"),"."),(0,r.kt)("li",{parentName:"ul"},"Long data ranges (several times longer than the ",(0,r.kt)("inlineCode",{parentName:"li"},"index_granularity"),") with identical values for ",(0,r.kt)("inlineCode",{parentName:"li"},"(a, b)")," are common. In other words, when adding another column allows you to skip quite long data ranges."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Improve data compression."),(0,r.kt)("p",{parentName:"li"},"ClickHouse sorts data by primary key, so the higher the consistency, the better the compression.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Provide additional logic when merging data parts in the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/collapsingmergetree#table_engine-collapsingmergetree"},"CollapsingMergeTree")," and ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/summingmergetree"},"SummingMergeTree")," engines."),(0,r.kt)("p",{parentName:"li"},"In this case it makes sense to specify the ",(0,r.kt)("em",{parentName:"p"},"sorting key")," that is different from the primary key."))),(0,r.kt)("p",null,"A long primary key will negatively affect the insert performance and memory consumption, but extra columns in the primary key do not affect ClickHouse performance during ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," queries."),(0,r.kt)("p",null,"You can create a table without a primary key using the ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY tuple()")," syntax. In this case, ClickHouse stores data in the order of inserting. If you want to save data order when inserting data by ",(0,r.kt)("inlineCode",{parentName:"p"},"INSERT ... SELECT")," queries, set ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#settings-max-insert-threads"},"max_insert_threads = 1"),"."),(0,r.kt)("p",null,"To select data in the initial order, use ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#settings-max_threads"},"single-threaded")," ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," queries."),(0,r.kt)("h3",{id:"choosing-a-primary-key-that-differs-from-the-sorting-key"},"Choosing a Primary Key that Differs from the Sorting Key"),(0,r.kt)("p",null,"It is possible to specify a primary key (an expression with values that are written in the index file for each mark) that is different from the sorting key (an expression for sorting the rows in data parts). In this case the primary key expression tuple must be a prefix of the sorting key expression tuple."),(0,r.kt)("p",null,"This feature is helpful when using the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/summingmergetree"},"SummingMergeTree")," and\n",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/aggregatingmergetree"},"AggregatingMergeTree")," table engines. In a common case when using these engines, the table has two types of columns: ",(0,r.kt)("em",{parentName:"p"},"dimensions")," and ",(0,r.kt)("em",{parentName:"p"},"measures"),". Typical queries aggregate values of measure columns with arbitrary ",(0,r.kt)("inlineCode",{parentName:"p"},"GROUP BY")," and filtering by dimensions. Because SummingMergeTree and AggregatingMergeTree aggregate rows with the same value of the sorting key, it is natural to add all dimensions to it. As a result, the key expression consists of a long list of columns and this list must be frequently updated with newly added dimensions."),(0,r.kt)("p",null,"In this case it makes sense to leave only a few columns in the primary key that will provide efficient range scans and add the remaining dimension columns to the sorting key tuple."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/alter/"},"ALTER")," of the sorting key is a lightweight operation because when a new column is simultaneously added to the table and to the sorting key, existing data parts do not need to be changed. Since the old sorting key is a prefix of the new sorting key and there is no data in the newly added column, the data is sorted by both the old and new sorting keys at the moment of table modification."),(0,r.kt)("h3",{id:"use-of-indexes-and-partitions-in-queries"},"Use of Indexes and Partitions in Queries"),(0,r.kt)("p",null,"For ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," queries, ClickHouse analyzes whether an index can be used. An index can be used if the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHERE/PREWHERE")," clause has an expression (as one of the conjunction elements, or entirely) that represents an equality or inequality comparison operation, or if it has ",(0,r.kt)("inlineCode",{parentName:"p"},"IN")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"LIKE")," with a fixed prefix on columns or expressions that are in the primary key or partitioning key, or on certain partially repetitive functions of these columns, or logical relationships of these expressions."),(0,r.kt)("p",null,"Thus, it is possible to quickly run queries on one or many ranges of the primary key. In this example, queries will be fast when run for a specific tracking tag, for a specific tag and date range, for a specific tag and date, for multiple tags with a date range, and so on."),(0,r.kt)("p",null,"Let\u2019s look at the engine configured as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  ENGINE MergeTree() PARTITION BY toYYYYMM(EventDate) ORDER BY (CounterID, EventDate) SETTINGS index_granularity=8192\n")),(0,r.kt)("p",null,"In this case, in queries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT count() FROM table WHERE EventDate = toDate(now()) AND CounterID = 34\nSELECT count() FROM table WHERE EventDate = toDate(now()) AND (CounterID = 34 OR CounterID = 42)\nSELECT count() FROM table WHERE ((EventDate >= toDate('2014-01-01') AND EventDate <= toDate('2014-01-31')) OR EventDate = toDate('2014-05-01')) AND CounterID IN (101500, 731962, 160656) AND (CounterID = 101500 OR EventDate != toDate('2014-05-01'))\n")),(0,r.kt)("p",null,"ClickHouse will use the primary key index to trim improper data and the monthly partitioning key to trim partitions that are in improper date ranges."),(0,r.kt)("p",null,"The queries above show that the index is used even for complex expressions. Reading from the table is organized so that using the index can\u2019t be slower than a full scan."),(0,r.kt)("p",null,"In the example below, the index can\u2019t be used."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT count() FROM table WHERE CounterID = 34 OR URL LIKE '%upyachka%'\n")),(0,r.kt)("p",null,"To check whether ClickHouse can use the index when running a query, use the settings ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#settings-force_index_by_date"},"force_index_by_date")," and ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#force-primary-key"},"force_primary_key"),"."),(0,r.kt)("p",null,"The key for partitioning by month allows reading only those data blocks which contain dates from the proper range. In this case, the data block may contain data for many dates (up to an entire month). Within a block, data is sorted by primary key, which might not contain the date as the first column. Because of this, using a query with only a date condition that does not specify the primary key prefix will cause more data to be read than for a single date."),(0,r.kt)("h3",{id:"use-of-index-for-partially-monotonic-primary-keys"},"Use of Index for Partially-monotonic Primary Keys"),(0,r.kt)("p",null,"Consider, for example, the days of the month. They form a ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Monotonic_function"},"monotonic sequence")," for one month, but not monotonic for more extended periods. This is a partially-monotonic sequence. If a user creates the table with partially-monotonic primary key, ClickHouse creates a sparse index as usual. When a user selects data from this kind of table, ClickHouse analyzes the query conditions. If the user wants to get data between two marks of the index and both these marks fall within one month, ClickHouse can use the index in this particular case because it can calculate the distance between the parameters of a query and index marks."),(0,r.kt)("p",null,"ClickHouse cannot use an index if the values of the primary key in the query parameter range do not represent a monotonic sequence. In this case, ClickHouse uses the full scan method."),(0,r.kt)("p",null,"ClickHouse uses this logic not only for days of the month sequences, but for any primary key that represents a partially-monotonic sequence."),(0,r.kt)("h3",{id:"table_engine-mergetree-data_skipping-indexes"},"Data Skipping Indexes"),(0,r.kt)("p",null,"The index declaration is in the columns section of the ",(0,r.kt)("inlineCode",{parentName:"p"},"CREATE")," query."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"INDEX index_name expr TYPE type(...) GRANULARITY granularity_value\n")),(0,r.kt)("p",null,"For tables from the ",(0,r.kt)("inlineCode",{parentName:"p"},"*MergeTree")," family, data skipping indices can be specified."),(0,r.kt)("p",null,"These indices aggregate some information about the specified expression on blocks, which consist of ",(0,r.kt)("inlineCode",{parentName:"p"},"granularity_value")," granules (the size of the granule is specified using the ",(0,r.kt)("inlineCode",{parentName:"p"},"index_granularity")," setting in the table engine). Then these aggregates are used in ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," queries for reducing the amount of data to read from the disk by skipping big blocks of data where the ",(0,r.kt)("inlineCode",{parentName:"p"},"where")," query cannot be satisfied."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Example")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE table_name\n(\n    u64 UInt64,\n    i32 Int32,\n    s String,\n    ...\n    INDEX a (u64 * i32, s) TYPE minmax GRANULARITY 3,\n    INDEX b (u64 * length(s)) TYPE set(1000) GRANULARITY 4\n) ENGINE = MergeTree()\n...\n")),(0,r.kt)("p",null,"Indices from the example can be used by ClickHouse to reduce the amount of data to read from disk in the following queries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT count() FROM table WHERE s &lt; 'z'\nSELECT count() FROM table WHERE u64 * i32 == 10 AND u64 * length(s) &gt;= 1234\n")),(0,r.kt)("h4",{id:"available-types-of-indices"},"Available Types of Indices"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"minmax")),(0,r.kt)("p",{parentName:"li"},"Stores extremes of the specified expression (if the expression is ",(0,r.kt)("inlineCode",{parentName:"p"},"tuple"),", then it stores extremes for each element of ",(0,r.kt)("inlineCode",{parentName:"p"},"tuple"),"), uses stored info for skipping blocks of data like the primary key.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"set(max_rows)")),(0,r.kt)("p",{parentName:"li"},"Stores unique values of the specified expression (no more than ",(0,r.kt)("inlineCode",{parentName:"p"},"max_rows")," rows, ",(0,r.kt)("inlineCode",{parentName:"p"},"max_rows=0")," means \u201cno limits\u201d). Uses the values to check if the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHERE")," expression is not satisfiable on a block of data.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"ngrambf_v1(n, size_of_bloom_filter_in_bytes, number_of_hash_functions, random_seed)")),(0,r.kt)("p",{parentName:"li"},"Stores a ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Bloom_filter"},"Bloom filter")," that contains all ngrams from a block of data. Works only with datatypes: ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/string"},"String"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/fixedstring"},"FixedString")," and ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/map"},"Map"),". Can be used for optimization of ",(0,r.kt)("inlineCode",{parentName:"p"},"EQUALS"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"LIKE")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"IN")," expressions."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"n")," \u2014 ngram size,"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"size_of_bloom_filter_in_bytes")," \u2014 Bloom filter size in bytes (you can use large values here, for example, 256 or 512, because it can be compressed well)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"number_of_hash_functions")," \u2014 The number of hash functions used in the Bloom filter."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"random_seed")," \u2014 The seed for Bloom filter hash functions."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"tokenbf_v1(size_of_bloom_filter_in_bytes, number_of_hash_functions, random_seed)")),(0,r.kt)("p",{parentName:"li"},"The same as ",(0,r.kt)("inlineCode",{parentName:"p"},"ngrambf_v1"),", but stores tokens instead of ngrams. Tokens are sequences separated by non-alphanumeric characters.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"bloom_filter([false_positive])")," \u2014 Stores a ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Bloom_filter"},"Bloom filter")," for the specified columns."),(0,r.kt)("p",{parentName:"li"},"The optional ",(0,r.kt)("inlineCode",{parentName:"p"},"false_positive")," parameter is the probability of receiving a false positive response from the filter. Possible values: (0, 1). Default value: 0.025."),(0,r.kt)("p",{parentName:"li"},"Supported data types: ",(0,r.kt)("inlineCode",{parentName:"p"},"Int*"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"UInt*"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Float*"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Enum"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Date"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"DateTime"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"String"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"FixedString"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Array"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"LowCardinality"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Nullable"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"UUID"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Map"),"."),(0,r.kt)("p",{parentName:"li"},"For ",(0,r.kt)("inlineCode",{parentName:"p"},"Map")," data type client can specify if index should be created for keys or values using ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/tuple-map-functions#mapkeys"},"mapKeys")," or ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/tuple-map-functions#mapvalues"},"mapValues")," function."),(0,r.kt)("p",{parentName:"li"},"The following functions can use the filter: ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions"},"equals"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions"},"notEquals"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/in-functions"},"in"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/in-functions"},"notIn"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/array-functions#hasarr-elem"},"has"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/array-functions#hasany"},"hasAny"),", ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/functions/array-functions#hasall"},"hasAll"),"."),(0,r.kt)("p",{parentName:"li"},"Example of index creation for ",(0,r.kt)("inlineCode",{parentName:"p"},"Map")," data type"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"INDEX map_key_index mapKeys(map_column) TYPE bloom_filter GRANULARITY 1\nINDEX map_key_index mapValues(map_column) TYPE bloom_filter GRANULARITY 1\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"INDEX sample_index (u64 * length(s)) TYPE minmax GRANULARITY 4\nINDEX sample_index2 (u64 * length(str), i32 + f64 * 100, date, str) TYPE set(100) GRANULARITY 4\nINDEX sample_index3 (lower(str), str) TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 4\n")),(0,r.kt)("h4",{id:"functions-support"},"Functions Support"),(0,r.kt)("p",null,"Conditions in the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHERE")," clause contains calls of the functions that operate with columns. If the column is a part of an index, ClickHouse tries to use this index when performing the functions. ClickHouse supports different subsets of functions for using indexes."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"set")," index can be used with all functions. Function subsets for other indexes are shown in the table below."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Function (operator) / Index"),(0,r.kt)("th",{parentName:"tr",align:null},"primary key"),(0,r.kt)("th",{parentName:"tr",align:null},"minmax"),(0,r.kt)("th",{parentName:"tr",align:null},"ngrambf_v1"),(0,r.kt)("th",{parentName:"tr",align:null},"tokenbf_v1"),(0,r.kt)("th",{parentName:"tr",align:null},"bloom_filter"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-equals"},"equals (=, ==)")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-notequals"},"notEquals(!=, ","<",">",")")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/string-search-functions#function-like"},"like")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/string-search-functions#function-notlike"},"notLike")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/string-functions#startswith"},"startsWith")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/string-functions#endswith"},"endsWith")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/string-search-functions#function-multisearchany"},"multiSearchAny")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/in-functions#in-functions"},"in")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/in-functions#in-functions"},"notIn")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-less"},"less (<)")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-greater"},"greater (>)")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-lessorequals"},"lessOrEquals (<=)")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/comparison-functions#function-greaterorequals"},"greaterOrEquals (>=)")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/array-functions#function-empty"},"empty")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/docs/staging1/docs/en/sql-reference/functions/array-functions#function-notempty"},"notEmpty")),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"hasToken"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2714"),(0,r.kt)("td",{parentName:"tr",align:null},"\u2717")))),(0,r.kt)("p",null,"Functions with a constant argument that is less than ngram size can\u2019t be used by ",(0,r.kt)("inlineCode",{parentName:"p"},"ngrambf_v1")," for query optimization."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Bloom filters can have false positive matches, so the ",(0,r.kt)("inlineCode",{parentName:"p"},"ngrambf_v1"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"tokenbf_v1"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"bloom_filter")," indexes can not be used for optimizing queries where the result of a function is expected to be false."),(0,r.kt)("p",{parentName:"div"},"For example:"),(0,r.kt)("ul",{parentName:"div"},(0,r.kt)("li",{parentName:"ul"},"Can be optimized:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"s LIKE '%test%'")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"NOT s NOT LIKE '%test%'")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"s = 1")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"NOT s != 1")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"startsWith(s, 'test')")))),(0,r.kt)("li",{parentName:"ul"},"Can not be optimized:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"NOT s LIKE '%test%'")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"s NOT LIKE '%test%'")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"NOT s = 1")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"s != 1")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"NOT startsWith(s, 'test')"))))))),(0,r.kt)("h2",{id:"projections"},"Projections"),(0,r.kt)("p",null,"Projections are like ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/create/view#materialized"},"materialized views")," but defined in part-level. It provides consistency guarantees along with automatic usage in queries."),(0,r.kt)("p",null,"Projections are an experimental feature. To enable them you must set the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#allow-experimental-projection-optimization"},"allow_experimental_projection_optimization")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"1"),". See also the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#force-optimize-projection"},"force_optimize_projection")," setting."),(0,r.kt)("p",null,"Projections are not supported in the ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," statements with the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/select/from#select-from-final"},"FINAL")," modifier."),(0,r.kt)("h3",{id:"projection-query"},"Projection Query"),(0,r.kt)("p",null,"A projection query is what defines a projection. It implicitly selects data from the parent table.\n",(0,r.kt)("strong",{parentName:"p"},"Syntax")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT <column list expr> [GROUP BY] <group keys expr> [ORDER BY] <expr>\n")),(0,r.kt)("p",null,"Projections can be modified or dropped with the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/alter/projection"},"ALTER")," statement."),(0,r.kt)("h3",{id:"projection-storage"},"Projection Storage"),(0,r.kt)("p",null,"Projections are stored inside the part directory. It's similar to an index but contains a subdirectory that stores an anonymous ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," table's part. The table is induced by the definition query of the projection. If there is a ",(0,r.kt)("inlineCode",{parentName:"p"},"GROUP BY")," clause, the underlying storage engine becomes ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/engines/table-engines/mergetree-family/aggregatingmergetree"},"AggregatingMergeTree"),", and all aggregate functions are converted to ",(0,r.kt)("inlineCode",{parentName:"p"},"AggregateFunction"),". If there is an ",(0,r.kt)("inlineCode",{parentName:"p"},"ORDER BY")," clause, the ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," table uses it as its primary key expression. During the merge process the projection part is merged via its storage's merge routine. The checksum of the parent table's part is combined with the projection's part. Other maintenance jobs are similar to skip indices."),(0,r.kt)("h3",{id:"projection-query-analysis"},"Query Analysis"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Check if the projection can be used to answer the given query, that is, it generates the same answer as querying the base table."),(0,r.kt)("li",{parentName:"ol"},"Select the best feasible match, which contains the least granules to read."),(0,r.kt)("li",{parentName:"ol"},'The query pipeline which uses projections will be different from the one that uses the original parts. If the projection is absent in some parts, we can add the pipeline to "project" it on the fly.')),(0,r.kt)("h2",{id:"concurrent-data-access"},"Concurrent Data Access"),(0,r.kt)("p",null,"For concurrent table access, we use multi-versioning. In other words, when a table is simultaneously read and updated, data is read from a set of parts that is current at the time of the query. There are no lengthy locks. Inserts do not get in the way of read operations."),(0,r.kt)("p",null,"Reading from a table is automatically parallelized."),(0,r.kt)("h2",{id:"table_engine-mergetree-ttl"},"TTL for Columns and Tables"),(0,r.kt)("p",null,"Determines the lifetime of values."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," clause can be set for the whole table and for each individual column. Table-level ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," can also specify the logic of automatic moving data between disks and volumes, or recompressing parts where all the data has been expired."),(0,r.kt)("p",null,"Expressions must evaluate to ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/date"},"Date")," or ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/data-types/datetime"},"DateTime")," data type."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Syntax")),(0,r.kt)("p",null,"Setting time-to-live for a column:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"TTL time_column\nTTL time_column + interval\n")),(0,r.kt)("p",null,"To define ",(0,r.kt)("inlineCode",{parentName:"p"},"interval"),", use ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/operators/#operators-datetime"},"time interval")," operators, for example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"TTL date_time + INTERVAL 1 MONTH\nTTL date_time + INTERVAL 15 HOUR\n")),(0,r.kt)("h3",{id:"mergetree-column-ttl"},"Column TTL"),(0,r.kt)("p",null,"When the values in the column expire, ClickHouse replaces them with the default values for the column data type. If all the column values in the data part expire, ClickHouse deletes this column from the data part in a filesystem."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," clause can\u2019t be used for key columns."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Examples")),(0,r.kt)("p",null,"Creating a table with ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE example_table\n(\n    d DateTime,\n    a Int TTL d + INTERVAL 1 MONTH,\n    b Int TTL d + INTERVAL 1 MONTH,\n    c String\n)\nENGINE = MergeTree\nPARTITION BY toYYYYMM(d)\nORDER BY d;\n")),(0,r.kt)("p",null,"Adding TTL to a column of an existing table"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE example_table\n    MODIFY COLUMN\n    c String TTL d + INTERVAL 1 DAY;\n")),(0,r.kt)("p",null,"Altering TTL of the column"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE example_table\n    MODIFY COLUMN\n    c String TTL d + INTERVAL 1 MONTH;\n")),(0,r.kt)("h3",{id:"mergetree-table-ttl"},"Table TTL"),(0,r.kt)("p",null,"Table can have an expression for removal of expired rows, and multiple expressions for automatic move of parts between ",(0,r.kt)("a",{parentName:"p",href:"#table_engine-mergetree-multiple-volumes"},"disks or volumes"),". When rows in the table expire, ClickHouse deletes all corresponding rows. For parts moving or recompressing, all rows of a part must satisfy the ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," expression criteria."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"TTL expr\n    [DELETE|RECOMPRESS codec_name1|TO DISK 'xxx'|TO VOLUME 'xxx'][, DELETE|RECOMPRESS codec_name2|TO DISK 'aaa'|TO VOLUME 'bbb'] ...\n    [WHERE conditions]\n    [GROUP BY key_expr [SET v1 = aggr_func(v1) [, v2 = aggr_func(v2) ...]] ]\n")),(0,r.kt)("p",null,"Type of TTL rule may follow each TTL expression. It affects an action which is to be done once the expression is satisfied (reaches current time):"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"DELETE")," - delete expired rows (default action);"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"RECOMPRESS codec_name")," - recompress data part with the ",(0,r.kt)("inlineCode",{parentName:"li"},"codec_name"),";"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"TO DISK 'aaa'")," - move part to the disk ",(0,r.kt)("inlineCode",{parentName:"li"},"aaa"),";"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"TO VOLUME 'bbb'")," - move part to the disk ",(0,r.kt)("inlineCode",{parentName:"li"},"bbb"),";"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"GROUP BY")," - aggregate expired rows.")),(0,r.kt)("p",null,"With ",(0,r.kt)("inlineCode",{parentName:"p"},"WHERE")," clause you may specify which of the expired rows to delete or aggregate (it cannot be applied to moves or recompression)."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"GROUP BY")," expression must be a prefix of the table primary key."),(0,r.kt)("p",null,"If a column is not part of the ",(0,r.kt)("inlineCode",{parentName:"p"},"GROUP BY")," expression and is not set explicitly in the ",(0,r.kt)("inlineCode",{parentName:"p"},"SET")," clause, in result row it contains an occasional value from the grouped rows (as if aggregate function ",(0,r.kt)("inlineCode",{parentName:"p"},"any")," is applied to it)."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Examples")),(0,r.kt)("p",null,"Creating a table with ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE example_table\n(\n    d DateTime,\n    a Int\n)\nENGINE = MergeTree\nPARTITION BY toYYYYMM(d)\nORDER BY d\nTTL d + INTERVAL 1 MONTH [DELETE],\n    d + INTERVAL 1 WEEK TO VOLUME 'aaa',\n    d + INTERVAL 2 WEEK TO DISK 'bbb';\n")),(0,r.kt)("p",null,"Altering ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," of the table:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE example_table\n    MODIFY TTL d + INTERVAL 1 DAY;\n")),(0,r.kt)("p",null,"Creating a table, where the rows are expired after one month. The expired rows where dates are Mondays are deleted:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE table_with_where\n(\n    d DateTime,\n    a Int\n)\nENGINE = MergeTree\nPARTITION BY toYYYYMM(d)\nORDER BY d\nTTL d + INTERVAL 1 MONTH DELETE WHERE toDayOfWeek(d) = 1;\n")),(0,r.kt)("p",null,"Creating a table, where expired rows are recompressed:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE table_for_recompression\n(\n    d DateTime,\n    key UInt64,\n    value String\n) ENGINE MergeTree()\nORDER BY tuple()\nPARTITION BY key\nTTL d + INTERVAL 1 MONTH RECOMPRESS CODEC(ZSTD(17)), d + INTERVAL 1 YEAR RECOMPRESS CODEC(LZ4HC(10))\nSETTINGS min_rows_for_wide_part = 0, min_bytes_for_wide_part = 0;\n")),(0,r.kt)("p",null,"Creating a table, where expired rows are aggregated. In result rows ",(0,r.kt)("inlineCode",{parentName:"p"},"x")," contains the maximum value accross the grouped rows, ",(0,r.kt)("inlineCode",{parentName:"p"},"y")," \u2014 the minimum value, and ",(0,r.kt)("inlineCode",{parentName:"p"},"d")," \u2014 any occasional value from grouped rows."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE table_for_aggregation\n(\n    d DateTime,\n    k1 Int,\n    k2 Int,\n    x Int,\n    y Int\n)\nENGINE = MergeTree\nORDER BY (k1, k2)\nTTL d + INTERVAL 1 MONTH GROUP BY k1, k2 SET x = max(x), y = min(y);\n")),(0,r.kt)("h3",{id:"mergetree-removing-expired-data"},"Removing Expired Data"),(0,r.kt)("p",null,"Data with an expired ",(0,r.kt)("inlineCode",{parentName:"p"},"TTL")," is removed when ClickHouse merges data parts."),(0,r.kt)("p",null,"When ClickHouse detects that data is expired, it performs an off-schedule merge. To control the frequency of such merges, you can set ",(0,r.kt)("inlineCode",{parentName:"p"},"merge_with_ttl_timeout"),". If the value is too low, it will perform many off-schedule merges that may consume a lot of resources."),(0,r.kt)("p",null,"If you perform the ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT")," query between merges, you may get expired data. To avoid it, use the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/optimize"},"OPTIMIZE")," query before ",(0,r.kt)("inlineCode",{parentName:"p"},"SELECT"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"See Also")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/settings/#ttl_only_drop_parts"},"ttl_only_drop_parts")," setting")),(0,r.kt)("h2",{id:"table_engine-mergetree-multiple-volumes"},"Using Multiple Block Devices for Data Storage"),(0,r.kt)("h3",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," family table engines can store data on multiple block devices. For example, it can be useful when the data of a certain table are implicitly split into \u201chot\u201d and \u201ccold\u201d. The most recent data is regularly requested but requires only a small amount of space. On the contrary, the fat-tailed historical data is requested rarely. If several disks are available, the \u201chot\u201d data may be located on fast disks (for example, NVMe SSDs or in memory), while the \u201ccold\u201d data - on relatively slow ones (for example, HDD)."),(0,r.kt)("p",null,"Data part is the minimum movable unit for ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree"),"-engine tables. The data belonging to one part are stored on one disk. Data parts can be moved between disks in the background (according to user settings) as well as by means of the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/alter/partition#alter_move-partition"},"ALTER")," queries."),(0,r.kt)("h3",{id:"terms"},"Terms"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Disk \u2014 Block device mounted to the filesystem."),(0,r.kt)("li",{parentName:"ul"},"Default disk \u2014 Disk that stores the path specified in the ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/operations/server-configuration-parameters/settings#server_configuration_parameters-path"},"path")," server setting."),(0,r.kt)("li",{parentName:"ul"},"Volume \u2014 Ordered set of equal disks (similar to ",(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Non-RAID_drive_architectures"},"JBOD"),")."),(0,r.kt)("li",{parentName:"ul"},"Storage policy \u2014 Set of volumes and the rules for moving data between them.")),(0,r.kt)("p",null,"The names given to the described entities can be found in the system tables, ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/system-tables/storage_policies#system_tables-storage_policies"},"system.storage_policies")," and ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/system-tables/disks#system_tables-disks"},"system.disks"),". To apply one of the configured storage policies for a table, use the ",(0,r.kt)("inlineCode",{parentName:"p"},"storage_policy")," setting of ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree"),"-engine family tables."),(0,r.kt)("h3",{id:"table_engine-mergetree-multiple-volumes_configure"},"Configuration"),(0,r.kt)("p",null,"Disks, volumes and storage policies should be declared inside the ",(0,r.kt)("inlineCode",{parentName:"p"},"<storage_configuration>")," tag either in the main file ",(0,r.kt)("inlineCode",{parentName:"p"},"config.xml")," or in a distinct file in the ",(0,r.kt)("inlineCode",{parentName:"p"},"config.d")," directory."),(0,r.kt)("p",null,"Configuration structure:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    <disks>\n        <disk_name_1> \x3c!-- disk name --\x3e\n            <path>/mnt/fast_ssd/clickhouse/</path>\n        </disk_name_1>\n        <disk_name_2>\n            <path>/mnt/hdd1/clickhouse/</path>\n            <keep_free_space_bytes>10485760</keep_free_space_bytes>\n        </disk_name_2>\n        <disk_name_3>\n            <path>/mnt/hdd2/clickhouse/</path>\n            <keep_free_space_bytes>10485760</keep_free_space_bytes>\n        </disk_name_3>\n\n        ...\n    </disks>\n\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"Tags:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"<disk_name_N>")," \u2014 Disk name. Names must be different for all disks."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"path")," \u2014 path under which a server will store data (",(0,r.kt)("inlineCode",{parentName:"li"},"data")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"shadow")," folders), should be terminated with \u2018/\u2019."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"keep_free_space_bytes")," \u2014 the amount of free disk space to be reserved.")),(0,r.kt)("p",null,"The order of the disk definition is not important."),(0,r.kt)("p",null,"Storage policies configuration markup:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    ...\n    <policies>\n        <policy_name_1>\n            <volumes>\n                <volume_name_1>\n                    <disk>disk_name_from_disks_configuration</disk>\n                    <max_data_part_size_bytes>1073741824</max_data_part_size_bytes>\n                </volume_name_1>\n                <volume_name_2>\n                    \x3c!-- configuration --\x3e\n                </volume_name_2>\n                \x3c!-- more volumes --\x3e\n            </volumes>\n            <move_factor>0.2</move_factor>\n        </policy_name_1>\n        <policy_name_2>\n            \x3c!-- configuration --\x3e\n        </policy_name_2>\n\n        \x3c!-- more policies --\x3e\n    </policies>\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"Tags:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"policy_name_N")," \u2014 Policy name. Policy names must be unique."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"volume_name_N")," \u2014 Volume name. Volume names must be unique."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"disk")," \u2014 a disk within a volume."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_data_part_size_bytes")," \u2014 the maximum size of a part that can be stored on any of the volume\u2019s disks. If the a size of a merged part estimated to be bigger than ",(0,r.kt)("inlineCode",{parentName:"li"},"max_data_part_size_bytes")," then this part will be written to a next volume. Basically this feature allows to keep new/small parts on a hot (SSD) volume and move them to a cold (HDD) volume when they reach large size. Do not use this setting if your policy has only one volume."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"move_factor")," \u2014 when the amount of available space gets lower than this factor, data automatically starts to move on the next volume if any (by default, 0.1). ClickHouse sorts existing parts by size from largest to smallest (in descending order) and selects parts with the total size that is sufficient to meet the ",(0,r.kt)("inlineCode",{parentName:"li"},"move_factor")," condition. If the total size of all parts is insufficient, all parts will be moved. "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"prefer_not_to_merge")," \u2014 Disables merging of data parts on this volume. When this setting is enabled, merging data on this volume is not allowed. This allows controlling how ClickHouse works with slow disks.")),(0,r.kt)("p",null,"Cofiguration examples:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    ...\n    <policies>\n        <hdd_in_order> \x3c!-- policy name --\x3e\n            <volumes>\n                <single> \x3c!-- volume name --\x3e\n                    <disk>disk1</disk>\n                    <disk>disk2</disk>\n                </single>\n            </volumes>\n        </hdd_in_order>\n\n        <moving_from_ssd_to_hdd>\n            <volumes>\n                <hot>\n                    <disk>fast_ssd</disk>\n                    <max_data_part_size_bytes>1073741824</max_data_part_size_bytes>\n                </hot>\n                <cold>\n                    <disk>disk1</disk>\n                </cold>\n            </volumes>\n            <move_factor>0.2</move_factor>\n        </moving_from_ssd_to_hdd>\n\n        <small_jbod_with_external_no_merges>\n            <volumes>\n                <main>\n                    <disk>jbod1</disk>\n                </main>\n                <external>\n                    <disk>external</disk>\n                    <prefer_not_to_merge>true</prefer_not_to_merge>\n                </external>\n            </volumes>\n        </small_jbod_with_external_no_merges>\n    </policies>\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"In given example, the ",(0,r.kt)("inlineCode",{parentName:"p"},"hdd_in_order")," policy implements the ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Round-robin_scheduling"},"round-robin")," approach. Thus this policy defines only one volume (",(0,r.kt)("inlineCode",{parentName:"p"},"single"),"), the data parts are stored on all its disks in circular order. Such policy can be quite useful if there are several similar disks are mounted to the system, but RAID is not configured. Keep in mind that each individual disk drive is not reliable and you might want to compensate it with replication factor of 3 or more."),(0,r.kt)("p",null,"If there are different kinds of disks available in the system, ",(0,r.kt)("inlineCode",{parentName:"p"},"moving_from_ssd_to_hdd")," policy can be used instead. The volume ",(0,r.kt)("inlineCode",{parentName:"p"},"hot")," consists of an SSD disk (",(0,r.kt)("inlineCode",{parentName:"p"},"fast_ssd"),"), and the maximum size of a part that can be stored on this volume is 1GB. All the parts with the size larger than 1GB will be stored directly on the ",(0,r.kt)("inlineCode",{parentName:"p"},"cold")," volume, which contains an HDD disk ",(0,r.kt)("inlineCode",{parentName:"p"},"disk1"),".\nAlso, once the disk ",(0,r.kt)("inlineCode",{parentName:"p"},"fast_ssd")," gets filled by more than 80%, data will be transferred to the ",(0,r.kt)("inlineCode",{parentName:"p"},"disk1")," by a background process."),(0,r.kt)("p",null,"The order of volume enumeration within a storage policy is important. Once a volume is overfilled, data are moved to the next one. The order of disk enumeration is important as well because data are stored on them in turns."),(0,r.kt)("p",null,"When creating a table, one can apply one of the configured storage policies to it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE table_with_non_default_policy (\n    EventDate Date,\n    OrderID UInt64,\n    BannerID UInt64,\n    SearchPhrase String\n) ENGINE = MergeTree\nORDER BY (OrderID, BannerID)\nPARTITION BY toYYYYMM(EventDate)\nSETTINGS storage_policy = 'moving_from_ssd_to_hdd'\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"default")," storage policy implies using only one volume, which consists of only one disk given in ",(0,r.kt)("inlineCode",{parentName:"p"},"<path>"),".\nYou could change storage policy after table creation with ","[ALTER TABLE ... MODIFY SETTING]"," query, new policy should include all old disks and volumes with same names."),(0,r.kt)("p",null,"The number of threads performing background moves of data parts can be changed by ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/#background_move_pool_size"},"background_move_pool_size")," setting."),(0,r.kt)("h3",{id:"details"},"Details"),(0,r.kt)("p",null,"In the case of ",(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," tables, data is getting to disk in different ways:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"As a result of an insert (",(0,r.kt)("inlineCode",{parentName:"li"},"INSERT")," query)."),(0,r.kt)("li",{parentName:"ul"},"During background merges and ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/sql-reference/statements/alter/#alter-mutations"},"mutations"),"."),(0,r.kt)("li",{parentName:"ul"},"When downloading from another replica."),(0,r.kt)("li",{parentName:"ul"},"As a result of partition freezing ",(0,r.kt)("a",{parentName:"li",href:"/docs/staging1/docs/en/sql-reference/statements/alter/partition#alter_freeze-partition"},"ALTER TABLE \u2026 FREEZE PARTITION"),".")),(0,r.kt)("p",null,"In all these cases except for mutations and partition freezing, a part is stored on a volume and a disk according to the given storage policy:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"The first volume (in the order of definition) that has enough disk space for storing a part (",(0,r.kt)("inlineCode",{parentName:"li"},"unreserved_space > current_part_size"),") and allows for storing parts of a given size (",(0,r.kt)("inlineCode",{parentName:"li"},"max_data_part_size_bytes > current_part_size"),") is chosen."),(0,r.kt)("li",{parentName:"ol"},"Within this volume, that disk is chosen that follows the one, which was used for storing the previous chunk of data, and that has free space more than the part size (",(0,r.kt)("inlineCode",{parentName:"li"},"unreserved_space - keep_free_space_bytes > current_part_size"),").")),(0,r.kt)("p",null,"Under the hood, mutations and partition freezing make use of ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Hard_link"},"hard links"),". Hard links between different disks are not supported, therefore in such cases the resulting parts are stored on the same disks as the initial ones."),(0,r.kt)("p",null,"In the background, parts are moved between volumes on the basis of the amount of free space (",(0,r.kt)("inlineCode",{parentName:"p"},"move_factor")," parameter) according to the order the volumes are declared in the configuration file.\nData is never transferred from the last one and into the first one. One may use system tables ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/system-tables/part_log#system_tables-part-log"},"system.part_log")," (field ",(0,r.kt)("inlineCode",{parentName:"p"},"type = MOVE_PART"),") and ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/system-tables/parts#system_tables-parts"},"system.parts")," (fields ",(0,r.kt)("inlineCode",{parentName:"p"},"path")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"disk"),") to monitor background moves. Also, the detailed information can be found in server logs."),(0,r.kt)("p",null,"User can force moving a part or a partition from one volume to another using the query ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/sql-reference/statements/alter/partition#alter_move-partition"},"ALTER TABLE \u2026 MOVE PART","|","PARTITION \u2026 TO VOLUME","|","DISK \u2026"),", all the restrictions for background operations are taken into account. The query initiates a move on its own and does not wait for background operations to be completed. User will get an error message if not enough free space is available or if any of the required conditions are not met."),(0,r.kt)("p",null,"Moving data does not interfere with data replication. Therefore, different storage policies can be specified for the same table on different replicas."),(0,r.kt)("p",null,"After the completion of background merges and mutations, old parts are removed only after a certain amount of time (",(0,r.kt)("inlineCode",{parentName:"p"},"old_parts_lifetime"),").\nDuring this time, they are not moved to other volumes or disks. Therefore, until the parts are finally removed, they are still taken into account for evaluation of the occupied disk space."),(0,r.kt)("p",null,"User can assign new big parts to different disks of a ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Non-RAID_drive_architectures"},"JBOD")," volume in a balanced way using the ",(0,r.kt)("a",{parentName:"p",href:"/docs/staging1/docs/en/operations/settings/merge-tree-settings#min-bytes-to-rebalance-partition-over-jbod"},"min_bytes_to_rebalance_partition_over_jbod")," setting."),(0,r.kt)("h2",{id:"table_engine-mergetree-s3"},"Using S3 for Data Storage"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," family table engines can store data to ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/s3/"},"S3")," using a disk with type ",(0,r.kt)("inlineCode",{parentName:"p"},"s3"),"."),(0,r.kt)("p",null,"This feature is under development and not ready for production. There are known drawbacks such as very low performance."),(0,r.kt)("p",null,"Configuration markup:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    ...\n    <disks>\n        <s3>\n            <type>s3</type>\n            <endpoint>https://clickhouse-public-datasets.s3.amazonaws.com/my-bucket/root-path/</endpoint>\n            <access_key_id>your_access_key_id</access_key_id>\n            <secret_access_key>your_secret_access_key</secret_access_key>\n            <region></region>\n            <server_side_encryption_customer_key_base64>your_base64_encoded_customer_key</server_side_encryption_customer_key_base64>\n            <proxy>\n                <uri>http://proxy1</uri>\n                <uri>http://proxy2</uri>\n            </proxy>\n            <connect_timeout_ms>10000</connect_timeout_ms>\n            <request_timeout_ms>5000</request_timeout_ms>\n            <retry_attempts>10</retry_attempts>\n            <single_read_retries>4</single_read_retries>\n            <min_bytes_for_seek>1000</min_bytes_for_seek>\n            <metadata_path>/var/lib/clickhouse/disks/s3/</metadata_path>\n            <cache_enabled>true</cache_enabled>\n            <cache_path>/var/lib/clickhouse/disks/s3/cache/</cache_path>\n            <skip_access_check>false</skip_access_check>\n        </s3>\n    </disks>\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"Required parameters:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"endpoint")," \u2014 S3 endpoint URL in ",(0,r.kt)("inlineCode",{parentName:"li"},"path")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"virtual hosted")," ",(0,r.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html"},"styles"),". Endpoint URL should contain a bucket and root path to store data."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"access_key_id")," \u2014 S3 access key id."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"secret_access_key")," \u2014 S3 secret access key.")),(0,r.kt)("p",null,"Optional parameters:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"region")," \u2014 S3 region name."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"use_environment_credentials")," \u2014 Reads AWS credentials from the Environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN if they exist. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"false"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"use_insecure_imds_request")," \u2014 If set to ",(0,r.kt)("inlineCode",{parentName:"li"},"true"),", S3 client will use insecure IMDS request while obtaining credentials from Amazon EC2 metadata. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"false"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"proxy")," \u2014 Proxy configuration for S3 endpoint. Each ",(0,r.kt)("inlineCode",{parentName:"li"},"uri")," element inside ",(0,r.kt)("inlineCode",{parentName:"li"},"proxy")," block should contain a proxy URL."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"connect_timeout_ms")," \u2014 Socket connect timeout in milliseconds. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"10 seconds"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"request_timeout_ms")," \u2014 Request timeout in milliseconds. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"5 seconds"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"retry_attempts")," \u2014 Number of retry attempts in case of failed request. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"10"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"single_read_retries")," \u2014 Number of retry attempts in case of connection drop during read. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"4"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_bytes_for_seek")," \u2014 Minimal number of bytes to use seek operation instead of sequential read. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"1 Mb"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"metadata_path")," \u2014 Path on local FS to store metadata files for S3. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"/var/lib/clickhouse/disks/<disk_name>/"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_enabled")," \u2014 Allows to cache mark and index files on local FS. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"true"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_path")," \u2014 Path on local FS where to store cached mark and index files. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"/var/lib/clickhouse/disks/<disk_name>/cache/"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"skip_access_check")," \u2014 If true, disk access checks will not be performed on disk start-up. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"false"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"server_side_encryption_customer_key_base64")," \u2014 If specified, required headers for accessing S3 objects with SSE-C encryption will be set.")),(0,r.kt)("p",null,"S3 disk can be configured as ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"cold")," storage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    ...\n    <disks>\n        <s3>\n            <type>s3</type>\n            <endpoint>https://clickhouse-public-datasets.s3.amazonaws.com/my-bucket/root-path/</endpoint>\n            <access_key_id>your_access_key_id</access_key_id>\n            <secret_access_key>your_secret_access_key</secret_access_key>\n        </s3>\n    </disks>\n    <policies>\n        <s3_main>\n            <volumes>\n                <main>\n                    <disk>s3</disk>\n                </main>\n            </volumes>\n        </s3_main>\n        <s3_cold>\n            <volumes>\n                <main>\n                    <disk>default</disk>\n                </main>\n                <external>\n                    <disk>s3</disk>\n                </external>\n            </volumes>\n            <move_factor>0.2</move_factor>\n        </s3_cold>\n    </policies>\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"In case of ",(0,r.kt)("inlineCode",{parentName:"p"},"cold")," option a data can be moved to S3 if local disk free size will be smaller than ",(0,r.kt)("inlineCode",{parentName:"p"},"move_factor * disk_size")," or by TTL move rule."),(0,r.kt)("h2",{id:"table_engine-mergetree-azure-blob-storage"},"Using Azure Blob Storage for Data Storage"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"MergeTree")," family table engines can store data to ",(0,r.kt)("a",{parentName:"p",href:"https://azure.microsoft.com/en-us/services/storage/blobs/"},"Azure Blob Storage")," using a disk with type ",(0,r.kt)("inlineCode",{parentName:"p"},"azure_blob_storage"),"."),(0,r.kt)("p",null,"As of February 2022, this feature is still a fresh addition, so expect that some Azure Blob Storage functionalities might be unimplemented."),(0,r.kt)("p",null,"Configuration markup:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<storage_configuration>\n    ...\n    <disks>\n        <blob_storage_disk>\n            <type>azure_blob_storage</type>\n            <storage_account_url>http://account.blob.core.windows.net</storage_account_url>\n            <container_name>container</container_name>\n            <account_name>account</account_name>\n            <account_key>pass123</account_key>\n            <metadata_path>/var/lib/clickhouse/disks/blob_storage_disk/</metadata_path>\n            <cache_enabled>true</cache_enabled>\n            <cache_path>/var/lib/clickhouse/disks/blob_storage_disk/cache/</cache_path>\n            <skip_access_check>false</skip_access_check>\n        </blob_storage_disk>\n    </disks>\n    ...\n</storage_configuration>\n")),(0,r.kt)("p",null,"Connection parameters:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"storage_account_url")," - ",(0,r.kt)("strong",{parentName:"li"},"Required"),", Azure Blob Storage account URL, like ",(0,r.kt)("inlineCode",{parentName:"li"},"http://account.blob.core.windows.net")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"http://azurite1:10000/devstoreaccount1"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"container_name")," - Target container name, defaults to ",(0,r.kt)("inlineCode",{parentName:"li"},"default-container"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"container_already_exists")," - If set to ",(0,r.kt)("inlineCode",{parentName:"li"},"false"),", a new container ",(0,r.kt)("inlineCode",{parentName:"li"},"container_name")," is created in the storage account, if set to ",(0,r.kt)("inlineCode",{parentName:"li"},"true"),", disk connects to the container directly, and if left unset, disk connects to the account, checks if the container ",(0,r.kt)("inlineCode",{parentName:"li"},"container_name")," exists, and creates it if it doesn't exist yet.")),(0,r.kt)("p",null,"Authentication parameters (the disk will try all available methods ",(0,r.kt)("strong",{parentName:"p"},"and")," Managed Identity Credential):"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"connection_string")," - For authentication using a connection string."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"account_name")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"account_key")," - For authentication using Shared Key.")),(0,r.kt)("p",null,"Limit parameters (mainly for internal usage):"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_single_part_upload_size")," - Limits the size of a single block upload to Blob Storage."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"min_bytes_for_seek")," - Limits the size of a seekable region."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_single_read_retries")," - Limits the number of attempts to read a chunk of data from Blob Storage."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"max_single_download_retries")," - Limits the number of attempts to download a readable buffer from Blob Storage."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"thread_pool_size")," - Limits the number of threads with which ",(0,r.kt)("inlineCode",{parentName:"li"},"IDiskRemote")," is instantiated.")),(0,r.kt)("p",null,"Other parameters:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"metadata_path")," - Path on local FS to store metadata files for Blob Storage. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"/var/lib/clickhouse/disks/<disk_name>/"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_enabled")," - Allows to cache mark and index files on local FS. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"true"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_path")," - Path on local FS where to store cached mark and index files. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"/var/lib/clickhouse/disks/<disk_name>/cache/"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"skip_access_check")," - If true, disk access checks will not be performed on disk start-up. Default value is ",(0,r.kt)("inlineCode",{parentName:"li"},"false"),".")),(0,r.kt)("p",null,"Examples of working configurations can be found in integration tests directory (see e.g. ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_merge_tree_azure_blob_storage/configs/config.d/storage_conf.xml"},"test_merge_tree_azure_blob_storage")," or ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_azure_blob_storage_zero_copy_replication/configs/config.d/storage_conf.xml"},"test_azure_blob_storage_zero_copy_replication"),")."),(0,r.kt)("h2",{id:"virtual-columns"},"Virtual Columns"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_part")," \u2014 Name of a part."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_part_index")," \u2014 Sequential index of the part in the query result."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_partition_id")," \u2014 Name of a partition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_part_uuid")," \u2014 Unique part identifier (if enabled MergeTree setting ",(0,r.kt)("inlineCode",{parentName:"li"},"assign_part_uuids"),")."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_partition_value")," \u2014 Values (a tuple) of a ",(0,r.kt)("inlineCode",{parentName:"li"},"partition by")," expression."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"_sample_factor")," \u2014 Sample factor (from the query).")))}c.isMDXComponent=!0}}]);